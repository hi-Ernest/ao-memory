#!/usr/bin/env npx ts-node

// é«˜çº§ API æµ‹è¯•è„šæœ¬ - æµ‹è¯• LangChain é›†æˆå’Œåæ€åŠŸèƒ½
// ç”¨æ³•: npx ts-node test-advanced.ts

const BASE_URL = 'http://localhost:8787';

async function testAdvancedAPI() {
  console.log('ğŸ§ª å¼€å§‹æµ‹è¯•é«˜çº§ Gateway APIï¼ˆLangChain é›†æˆï¼‰...\n');

  try {
    const user_id = 'test_user_' + Date.now();

    // 1. æµ‹è¯•é«˜çº§è®°å¿†ä¿å­˜ï¼ˆLangChain æ¶ˆæ¯æ ¼å¼ï¼‰
    console.log('1ï¸âƒ£ æµ‹è¯•é«˜çº§è®°å¿†ä¿å­˜ï¼ˆLangChain æ¶ˆæ¯æ ¼å¼ï¼‰...');
    const saveAdvancedResponse = await fetch(`${BASE_URL}/api/memory/save-advanced`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        user_id,
        messages: [
          {
            type: 'system',
            content: 'You are a helpful research assistant specialized in machine learning papers.'
          },
          {
            type: 'human',
            content: 'Can you explain how transformer attention mechanisms work in the context of the original "Attention is All You Need" paper?'
          },
          {
            type: 'ai',
            content: 'The transformer attention mechanism works by computing scaled dot-product attention. For each query Q, key K, and value V, it calculates attention weights using the formula: Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V. This allows the model to focus on relevant parts of the input sequence when processing each position. The multi-head attention then runs multiple attention functions in parallel, enabling the model to attend to information from different representation subspaces simultaneously.'
          },
          {
            type: 'human',
            content: 'How does this compare to RNN-based attention?'
          },
          {
            type: 'ai',
            content: 'Unlike RNN-based attention which processes sequences sequentially, transformer attention allows for parallel computation of all positions simultaneously. This makes training much faster and enables better handling of long-range dependencies. RNN attention typically uses hidden states from previous time steps, while transformer attention directly computes relationships between all pairs of positions in the sequence.'
          }
        ]
      })
    });
    
    if (saveAdvancedResponse.ok) {
      const saveResult = await saveAdvancedResponse.json();
      console.log('âœ… é«˜çº§è®°å¿†ä¿å­˜æˆåŠŸ:');
      console.log('   ç”¨æˆ·ID:', saveResult.user_id);
      console.log('   è®°å¿†ID:', saveResult.id);
      console.log('   LLM ç”Ÿæˆçš„åæ€æ•°æ®:');
      console.log('     ä¸Šä¸‹æ–‡æ ‡ç­¾:', saveResult.reflection?.context_tags);
      console.log('     å¯¹è¯æ‘˜è¦:', saveResult.reflection?.conversation_summary);
      console.log('     æœ‰æ•ˆæ–¹æ³•:', saveResult.reflection?.what_worked);
      console.log('     é¿å…äº‹é¡¹:', saveResult.reflection?.what_to_avoid);
    } else {
      console.log('âŒ é«˜çº§è®°å¿†ä¿å­˜å¤±è´¥:', await saveAdvancedResponse.text());
      return;
    }

    // 2. ä¿å­˜ç¬¬äºŒä¸ªè®°å¿†ï¼ˆä¸åŒä¸»é¢˜ï¼‰
    console.log('\n2ï¸âƒ£ ä¿å­˜ç¬¬äºŒä¸ªè®°å¿†ï¼ˆæ·±åº¦å­¦ä¹ ä¼˜åŒ–ï¼‰...');
    const saveAdvanced2Response = await fetch(`${BASE_URL}/api/memory/save-advanced`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        user_id,
        messages: [
          {
            type: 'human',
            content: 'What are the key differences between Adam and SGD optimizers?'
          },
          {
            type: 'ai',
            content: 'Adam combines the benefits of two other extensions of SGD: AdaGrad and RMSProp. Key differences: 1) Adam uses adaptive learning rates for each parameter, while SGD uses a fixed rate. 2) Adam maintains running averages of both gradients and their squared values, providing momentum-like behavior. 3) SGD can be more sensitive to hyperparameter choices but sometimes achieves better generalization. 4) Adam typically converges faster but may get stuck in suboptimal solutions in some cases.'
          },
          {
            type: 'human',
            content: 'When should I use each one?'
          },
          {
            type: 'ai',
            content: 'Use Adam for: quick prototyping, RNNs, and when you need faster initial convergence. Use SGD with momentum for: final model training, when you have time to tune hyperparameters, and for potentially better generalization. Many practitioners start with Adam for rapid development, then switch to SGD for final optimization.'
          }
        ]
      })
    });
    
    if (saveAdvanced2Response.ok) {
      const saveResult2 = await saveAdvanced2Response.json();
      console.log('âœ… ç¬¬äºŒä¸ªè®°å¿†ä¿å­˜æˆåŠŸ');
      console.log('   åæ€æ‘˜è¦:', saveResult2.reflection?.conversation_summary);
    } else {
      console.log('âŒ ç¬¬äºŒä¸ªè®°å¿†ä¿å­˜å¤±è´¥:', await saveAdvanced2Response.text());
    }

    // 3. ç­‰å¾…æ•°æ®åŒæ­¥
    console.log('\nâ³ ç­‰å¾…æ•°æ®åŒæ­¥...');
    await new Promise(resolve => setTimeout(resolve, 3000));

    // 4. æµ‹è¯•é«˜çº§è®°å¿†æŸ¥è¯¢ï¼ˆç³»ç»Ÿæç¤ºç”Ÿæˆï¼‰
    console.log('\n3ï¸âƒ£ æµ‹è¯•é«˜çº§è®°å¿†æŸ¥è¯¢å’Œç³»ç»Ÿæç¤ºç”Ÿæˆ...');
    const recallResponse = await fetch(`${BASE_URL}/api/memory/recall`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query: 'explain machine learning concepts to beginners',
        user_id,
        limit: 2,
        alpha: 0.6
      })
    });
    
    if (recallResponse.ok) {
      const recallResult = await recallResponse.json();
      console.log('âœ… é«˜çº§è®°å¿†æŸ¥è¯¢æˆåŠŸ:');
      console.log(`   æ‰¾åˆ° ${recallResult.memory.length} ä¸ªç›¸å…³è®°å¿†`);
      
      recallResult.memory.forEach((memory: any, index: number) => {
        console.log(`\n   ğŸ“ è®°å¿† ${index + 1}:`);
        console.log(`      ç›¸å…³æ€§å¾—åˆ†: ${memory.score.toFixed(3)}`);
        console.log(`      ä¸Šä¸‹æ–‡æ ‡ç­¾: ${memory.context_tags?.join(', ')}`);
        console.log(`      å¯¹è¯æ‘˜è¦: ${memory.conversation_summary}`);
        console.log(`      æœ‰æ•ˆæ–¹æ³•: ${memory.what_worked}`);
      });

      console.log('\n   ğŸ¯ ç”Ÿæˆçš„ç³»ç»Ÿæç¤º:');
      console.log(`   "${recallResult.system_prompt.substring(0, 200)}..."`);
      
      console.log('\n   ğŸ“Š å…¨å±€ç»Ÿè®¡:');
      console.log(`      æ€»å¯¹è¯æ•°: ${recallResult.global_stats.total_conversations}`);
      console.log(`      æœ‰æ•ˆæ–¹æ³•æ•°: ${recallResult.global_stats.what_worked_count}`);
      console.log(`      é¿å…äº‹é¡¹æ•°: ${recallResult.global_stats.what_to_avoid_count}`);
    } else {
      console.log('âŒ é«˜çº§è®°å¿†æŸ¥è¯¢å¤±è´¥:', await recallResponse.text());
    }

    // 5. æµ‹è¯•ä¸åŒç”¨æˆ·çš„è®°å¿†éš”ç¦»
    console.log('\n4ï¸âƒ£ æµ‹è¯•ç”¨æˆ·è®°å¿†éš”ç¦»...');
    const anotherUserId = 'another_user_' + Date.now();
    
    const isolationTestResponse = await fetch(`${BASE_URL}/api/memory/recall`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query: 'transformer attention mechanisms',
        user_id: anotherUserId, // ä¸åŒçš„ç”¨æˆ·ID
        limit: 2
      })
    });
    
    if (isolationTestResponse.ok) {
      const isolationResult = await isolationTestResponse.json();
      console.log('âœ… ç”¨æˆ·éš”ç¦»æµ‹è¯•æˆåŠŸ:');
      console.log(`   æ–°ç”¨æˆ· ${anotherUserId} çš„è®°å¿†æ•°: ${isolationResult.memory.length}`);
      console.log(`   æ€»å¯¹è¯æ•°: ${isolationResult.global_stats.total_conversations}`);
      
      if (isolationResult.memory.length === 0) {
        console.log('   âœ… è®°å¿†éš”ç¦»æ­£å¸¸ - æ–°ç”¨æˆ·æ²¡æœ‰è®¿é—®åˆ°å…¶ä»–ç”¨æˆ·çš„è®°å¿†');
      } else {
        console.log('   âš ï¸ è®°å¿†éš”ç¦»å¯èƒ½æœ‰é—®é¢˜ - æ–°ç”¨æˆ·çœ‹åˆ°äº†è®°å¿†');
      }
    } else {
      console.log('âŒ ç”¨æˆ·éš”ç¦»æµ‹è¯•å¤±è´¥:', await isolationTestResponse.text());
    }

    // 6. æµ‹è¯•ç³»ç»Ÿæç¤ºçš„æ¸è¿›ç´¯ç§¯
    console.log('\n5ï¸âƒ£ æµ‹è¯•ç³»ç»Ÿæç¤ºçš„æ¸è¿›ç´¯ç§¯...');
    
    // å†æ¬¡æŸ¥è¯¢åŸç”¨æˆ·ï¼Œçœ‹ç³»ç»Ÿæç¤ºæ˜¯å¦åŒ…å«äº†ç´¯ç§¯çš„ä¿¡æ¯
    const accumulationResponse = await fetch(`${BASE_URL}/api/memory/recall`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query: 'deep learning optimization techniques',
        user_id, // åŸç”¨æˆ·
        limit: 2
      })
    });
    
    if (accumulationResponse.ok) {
      const accumulationResult = await accumulationResponse.json();
      console.log('âœ… ç³»ç»Ÿæç¤ºç´¯ç§¯æµ‹è¯•æˆåŠŸ:');
      console.log(`   ç´¯ç§¯çš„æ€»å¯¹è¯æ•°: ${accumulationResult.global_stats.total_conversations}`);
      console.log(`   ç´¯ç§¯çš„æœ‰æ•ˆæ–¹æ³•: ${accumulationResult.global_stats.what_worked_count}`);
      
      // æ£€æŸ¥ç³»ç»Ÿæç¤ºæ˜¯å¦åŒ…å«ä¹‹å‰çš„å­¦ä¹ å†…å®¹
      const systemPrompt = accumulationResult.system_prompt;
      const hasTransformerContent = systemPrompt.includes('transformer') || systemPrompt.includes('attention');
      const hasOptimizerContent = systemPrompt.includes('Adam') || systemPrompt.includes('SGD') || systemPrompt.includes('optimizer');
      
      console.log('   ğŸ” ç³»ç»Ÿæç¤ºå†…å®¹åˆ†æ:');
      console.log(`      åŒ…å«Transformerç›¸å…³å†…å®¹: ${hasTransformerContent ? 'âœ…' : 'âŒ'}`);
      console.log(`      åŒ…å«ä¼˜åŒ–å™¨ç›¸å…³å†…å®¹: ${hasOptimizerContent ? 'âœ…' : 'âŒ'}`);
      
      if (hasTransformerContent && hasOptimizerContent) {
        console.log('   ğŸ‰ ç³»ç»Ÿæç¤ºæˆåŠŸç´¯ç§¯äº†å¤šä¸ªå¯¹è¯çš„å­¦ä¹ å†…å®¹ï¼');
      }
    } else {
      console.log('âŒ ç³»ç»Ÿæç¤ºç´¯ç§¯æµ‹è¯•å¤±è´¥:', await accumulationResponse.text());
    }

    console.log('\nğŸ‰ æ‰€æœ‰é«˜çº§ API æµ‹è¯•å®Œæˆï¼');
    console.log('\nğŸ” æµ‹è¯•æ€»ç»“:');
    console.log('âœ… LangChain æ¶ˆæ¯æ ¼å¼æ”¯æŒ');
    console.log('âœ… LLM é©±åŠ¨çš„åæ€ç”Ÿæˆ');
    console.log('âœ… ç”¨æˆ·è®°å¿†éš”ç¦»');
    console.log('âœ… ç³»ç»Ÿæç¤ºè‡ªåŠ¨ç”Ÿæˆ');
    console.log('âœ… è®°å¿†å†…å®¹ç´¯ç§¯');

  } catch (error) {
    console.error('ğŸ’¥ é«˜çº§ API æµ‹è¯•å¤±è´¥:', error);
  }
}

// è¿è¡Œæµ‹è¯•
if (import.meta.url === `file://${process.argv[1]}`) {
  testAdvancedAPI().catch(console.error);
}

export { testAdvancedAPI };
